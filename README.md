该项目使用rag和kg技术构建问答系统
# rag的算法流程
1. 使用动态切分的方法将文档切块
2. 使用bert模型将文本块转化成高维向量，存入到faiss向量数据库中
3. 将query同样向量化，使用近似最近邻算法进行比对，得到最相关的文档内容
4. 使用文档重排序和上下文融合技术，对检索到的文档内容进行处理
5. 将处理后的文档传入到LLM中生成回答
# 文本切分算法
## 动态切分算法说明
根据标点符号将文本切分成一个个句子，计算句子长度
如果单句长度大于限制的话，用滑窗切分为多个子块，加入到结果列表中，这个滑窗是有一定重叠的
如果单句长度+现有的块长度不超过上限的话，加入到现有块，继续进行
如果单句长度+现有块长度超过上限，把现有文本块收尾，将现有文本块的结尾作为开头，加上该单句，继续组装新块
## 递归分块
先设置多级分隔符，章节两个及以上换行符，段落一个换行符，句子标点，先看当前文本长度，如果当前文本长度小于max_tokens，直接返回，不满足的情况下就
看是否有可用的分隔符，有可用的分隔符情况下，按当前分隔符切分成块集合，遍历块集合累加到一个缓存块中，如果加上当前块超过max_tokens，储存当前缓存块，如果
如果当前part大于max_tokens，就递归切分，否则当前part作为新的缓存块继续累加，如果用完分隔符part的大小还大于max_token，就直接按定长切分
## 语义分块
将文本切分成一个个句子，把连续的几个句子看成一个语义单元，计算这个单元的Embedding，然后比较相邻“单元”之间的语义距离，如果两个单元相似且不超过最大max_tokens，
将两个单元合并，否则断开
# 查询优化
利用模型改写用户的原始输入有助于检索器清晰地理解检索需求，返回更精确的结果
# 近似最近邻算法说明(从向量数据库中检索到相似文档块)
将向量库中的向量使用k-means算法进行聚类处理，分成几个簇，查询时直接query向量与聚类中心进行比较，来确定他们所归属的簇，来加速搜索，对于每个簇中的向量
将其切分成子向量，子向量用其对应的子向量聚类中心的序号来代替，这样就极大减少了它的储存，同时还形成了码表，比如子向量一的所有聚类中心，子向量二的聚类中心，
在查询时，同样将query向量切分成若干子向量，与码表各个子向量的聚类中心计算欧式距离，形成距离表，这样，向量库中某一向量与query向量的距离就是距离表某一子向量序号代表距离表中的距离之和
这样就减少了储存，同时加快了距离计算
# 文档重排序
计算bm25分数和余弦相似度分数，取前面排名分数更高的文档，舍弃分数低的文档
bm25分数这里是关键词匹配
余弦相似度这里是语义相似性
# 上下文融合
两两计算文档的余弦相似度，将相似度高的文档合并
# rag这里处理多跳问题
子查询：将问题分解为子问题，通过解决子问题，再将子问题答案与下一个子问题相结合来进行检索得到新的回答，不断向下一个子问题添加新的提示从而解决最终的问题。
# KG算法原理
1. 知识抽取
2. 知识融合
3. 知识推理
# 知识抽取部分
大模型抽取加上Hanlp补充
1. 大模型抽取
将传入的文档切分为文档块，将文档块传入到大模型中让其抽取三元组，包括实体-关系-实体，实体-属性-属性值
2. Hanlp补充
对文本进行清洗，去除多余空格，换行符，以及其他特殊符号，使用NER（命名实体识别）识别出候选实体，使用依存句法分析，得到每个词的依存关系，
主要选取主谓关系和动宾关系，构建三元组，再使用规则匹配一些常见模式，进行去重
# 知识融合部分
将相似实体关系合并
对实体计算相似度，将相似的合并
# 知识推理
使用hanlp进行实体识别，从用户查询中提取实体，基于这些实体从数据库中提取相关的三元组，针对每一对实体，对其进行关系推理
启发式的路径排序算法
传入头实体，尾实体，关系，查询匹配的1-3跳路径，使用节点出度计算随机游走概率，保留路径>=2的结果，返回推理路径及对应的概率评分
# 大模型生成
对于简单问题，使用rag+kg混合检索的方式，将检索到的内容构建Prompt返回给LLM生成回答
对于复杂问题，也就是多推理问题，有两种pipline，一种就是rag加kg混合检索构建prompt返回给LLM生成答案，另一种就是使用子查询的方法，
将复杂问题分解为子问题，对于子问题进行检索得到回答，将回答与下一个子问题结合检索生成新的回答，不断向下一个子问题添加答案从而生成最终答案